{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, \\\n",
    "                                    GridSearchCV, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier,\\\n",
    "                             AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mframes\u001b[0m/                    README.txt                             Task1.ipynb\r\n",
      "\u001b[01;32mlunar_lander_data_gen.py\u001b[0m*  state_vectors_2018-04-21-20-41-25.csv\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plug in data file\n",
    "\n",
    "#Other\n",
    "#data_file = \"state_vectors_....etc.csv\"\n",
    "\n",
    "#Andy\n",
    "data_file = \"state_vectors_2018-04-21-20-41-25.csv\"\n",
    "\n",
    "#Conor\n",
    "#data_file = \"../state_vectors_2018-04-20-15-12-38.csv\"\n",
    "\n",
    "sample_nr_rows = 6000\n",
    "grid_search_cv_folds = 5\n",
    "cv_experiment_folds = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "df = pd.read_csv(data_file)\n",
    "\n",
    "# take sample of required size\n",
    "sample_df = df.sample(sample_nr_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into X,y (descriptive features, target feature)\n",
    "X,y = sample_df[[col for col in list(sample_df) if col!='action']], sample_df['action']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose 3 classifiers to go in here\n",
    "clfs = [RandomForestClassifier]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary for grid search parameters\n",
    "param_grids= {\n",
    "    'RandomForestClassifier': {\n",
    "        'criterion' : ['gini', 'entropy'],\n",
    "        'n_estimators' : [5,10,15],\n",
    "        'max_features' : [None, 5, 8]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary to store the best set of parameters and the best score for each clf\n",
    "tuned_clfs={}\n",
    "\n",
    "# running grid search for each clf\n",
    "for clf in clfs:\n",
    "    clf_name = str(clf).split(\".\")[-1][:-2]\n",
    "    current_GS = GridSearchCV(clf(), \n",
    "                              param_grids[clf_name],\n",
    "                              cv=grid_search_cv_folds,\n",
    "                              verbose=0, \n",
    "                              return_train_score=True).fit(X,y)\n",
    "    \n",
    "    # store best params and best score in a sub dictionary for clf\n",
    "    tuned_clfs[clf_name] = {\n",
    "                        'best_params' : current_GS.best_params_,\n",
    "                        'best_score' : current_GS.best_score_\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RandomForestClassifier': {'best_params': {'criterion': 'gini',\n",
      "                                            'max_features': 8,\n",
      "                                            'n_estimators': 15},\n",
      "                            'best_score': 0.82783333333333331}}\n"
     ]
    }
   ],
   "source": [
    "# print the best params and score for each clf\n",
    "pprint.pprint(tuned_clfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation experiment for clfs using hyper-params from above\n",
    "cv_scores = {}\n",
    "for clf in clfs:\n",
    "    clf_name = str(clf).split(\".\")[-1][:-2]\n",
    "    params = tuned_clfs[clf_name]['best_params']\n",
    "    cv_scores[clf_name] = np.mean(cross_val_score(clf(**params), X, y, cv=cv_experiment_folds)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RandomForestClassifier': 0.83115776288868237}\n"
     ]
    }
   ],
   "source": [
    "# print the avg cross validation scores for the clfs using their best params\n",
    "pprint.pprint(cv_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
